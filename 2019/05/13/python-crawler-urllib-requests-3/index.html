<!DOCTYPE HTML>
<html lang="zh-CN">


<head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="utf-8">
    <meta name="keywords" content="Python网络爬虫实战之三：基本工具库urllib和requests, 苦乐随缘">
    <meta name="description" content="Python网络爬虫实战之三：基本工具库urllib和requests一、urlliburllib简介urllib是Python中一个功能强大用于操作URL，并在爬虫时经常用到的一个基础库，无需额外安装，默认已经安装到python中。
ur">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>Python网络爬虫实战之三：基本工具库urllib和requests | 苦乐随缘</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    <style type="text/css">
        
    </style>

    <script src="/libs/jquery/jquery-2.2.0.min.js"></script>
<link rel="stylesheet" href="/Coderzgh.github.io/css/prism-tomorrow.css" type="text/css"></head>


<body>

<header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Coderzgh.github.io/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">苦乐随缘</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fa fa-navicon"></i></a>
<ul class="right">
    
    <li class="hide-on-med-and-down">
        <a href="/" class="waves-effect waves-light">
            
            <i class="fa fa-home"></i>
            
            <span>首页</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/tags" class="waves-effect waves-light">
            
            <i class="fa fa-tags"></i>
            
            <span>标签</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/categories" class="waves-effect waves-light">
            
            <i class="fa fa-bookmark"></i>
            
            <span>分类</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/archives" class="waves-effect waves-light">
            
            <i class="fa fa-archive"></i>
            
            <span>归档</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/about" class="waves-effect waves-light">
            
            <i class="fa fa-user-circle-o"></i>
            
            <span>关于</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/friends" class="waves-effect waves-light">
            
            <i class="fa fa-address-book"></i>
            
            <span>友情链接</span>
        </a>
    </li>
    
    <li>
        <a href="#searchModal" class="modal-trigger waves-effect waves-light">
            <i id="searchIcon" class="fa fa-search" title="搜索"></i>
        </a>
    </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">苦乐随缘</div>
        <div class="logo-desc">
            
            花不解语还多事  石不能言最可人
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li>
            <a href="/" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-home"></i>
                
                首页
            </a>
        </li>
        
        <li>
            <a href="/tags" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-tags"></i>
                
                标签
            </a>
        </li>
        
        <li>
            <a href="/categories" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-bookmark"></i>
                
                分类
            </a>
        </li>
        
        <li>
            <a href="/archives" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-archive"></i>
                
                归档
            </a>
        </li>
        
        <li>
            <a href="/about" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-user-circle-o"></i>
                
                关于
            </a>
        </li>
        
        <li>
            <a href="/friends" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-address-book"></i>
                
                友情链接
            </a>
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Coderzgh" class="waves-effect waves-light" target="_blank">
                <i class="fa fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Coderzgh" class="github-corner tooltipped hide-on-med-and-down" target="_blank" data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewbox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/>
    </svg>
</a>
        
    </nav>

</header>





<div class="bg-cover pd-header post-cover" style="background-image: url('/source/images/xxx.jpg')">
    <div class="container">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <div class="description center-align post-title">
                        Python网络爬虫实战之三：基本工具库urllib和requests
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>



<main class="container content">

    
    <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Coderzgh.github.io/tags/Python/" target="_blank">
                                <span class="chip bg-color">Python</span>
                            </a>
                        
                            <a href="/Coderzgh.github.io/tags/requests/" target="_blank">
                                <span class="chip bg-color">requests</span>
                            </a>
                        
                            <a href="/Coderzgh.github.io/tags/urllib/" target="_blank">
                                <span class="chip bg-color">urllib</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fa fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Coderzgh.github.io/categories/Python/" class="post-category" target="_blank">
                                Python
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                <div class="post-date info-break-policy">
                    <i class="fa fa-calendar-minus-o fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2019-05-13
                </div>

                
				
				
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="fa fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="Python网络爬虫实战之三：基本工具库urllib和requests"><a href="#Python网络爬虫实战之三：基本工具库urllib和requests" class="headerlink" title="Python网络爬虫实战之三：基本工具库urllib和requests"></a>Python网络爬虫实战之三：基本工具库urllib和requests</h1><h1 id="一、urllib"><a href="#一、urllib" class="headerlink" title="一、urllib"></a>一、urllib</h1><h3 id="urllib简介"><a href="#urllib简介" class="headerlink" title="urllib简介"></a>urllib简介</h3><p>urllib是Python中一个功能强大用于操作URL，并在爬虫时经常用到的一个基础库，无需额外安装，默认已经安装到python中。</p>
<h3 id="urllib在python2-x与python3-x中的区别"><a href="#urllib在python2-x与python3-x中的区别" class="headerlink" title="urllib在python2.x与python3.x中的区别"></a>urllib在python2.x与python3.x中的区别</h3><p>在python2.x中，urllib分为urllib和urllib2，在python3.x中合并为urllib。两者使用起来不太一样，注意转换。</p>
<table>
<thead>
<tr>
<th>Python2.x</th>
<th>Python3.x</th>
</tr>
</thead>
<tbody>
<tr>
<td>import urllib2</td>
<td>import urllib.request，urllib.error</td>
</tr>
<tr>
<td>import urllib</td>
<td>import urllib.request，urllib.error，urllib.parse</td>
</tr>
<tr>
<td>import urlparse</td>
<td>import urllib.parse</td>
</tr>
<tr>
<td>import urlopen</td>
<td>import urllib.request.urlopen</td>
</tr>
<tr>
<td>import urlencode</td>
<td>import urllib.parse.urlencode</td>
</tr>
<tr>
<td>import urllib.quote</td>
<td>import urllib.request.quote</td>
</tr>
<tr>
<td>cookielib.CookieJar</td>
<td>http.CookieJar</td>
</tr>
<tr>
<td>urllib2.Request</td>
<td>urllib.request.Request</td>
</tr>
</tbody>
</table>
<h3 id="urllib的四个子模块"><a href="#urllib的四个子模块" class="headerlink" title="urllib的四个子模块"></a>urllib的四个子模块</h3><p>Python3.6.0中urllib模块包括一下四个子模块，urllib模块是一个运用于URL的包（urllib is a package that collects several modules for working with URLs）</p>
<ul>
<li>urllib.request用于访问和读取URLS（urllib.request for opening and reading URLs），就像在浏览器里输入网址然后回车一样，只需要给这个库方法传入URL和其他参数就可以模拟实现这个过程。</li>
<li>urllib.error包括了所有urllib.request导致的异常（urllib.error containing the exceptions raised by urllib.request），我们可以捕捉这些异常，然后进行重试或者其他操作以确保程序不会意外终止。</li>
<li>urllib.parse用于解析URLS（urllib.parse for parsing URLs），提供了很多URL处理方法，比如拆分、解析、合并、编码。</li>
<li>urllib.robotparser用于解析robots.txt文件（urllib.robotparser for parsing robots.txt files），然后判断哪些网站可以爬，哪些网站不可以爬。</li>
</ul>
<h3 id="使用urllib打开网页"><a href="#使用urllib打开网页" class="headerlink" title="使用urllib打开网页"></a>使用urllib打开网页</h3><p>最基本的方法打开网页</p>
<pre><code># 最基本的方法打开网页
from urllib.request import urlopen

response = urlopen(&quot;http://www.baidu.com&quot;)
print(type(response))
print(response.status)
print(response.getheaders())
print(response.getheader(&#39;Server&#39;))
html = response.read()
print(html)
</code></pre><p>携带data参数打开网页</p>
<pre><code># 携带data参数打开网页
from urllib.parse import urlencode
from urllib.request import urlopen

data = bytes(urlencode({&#39;word&#39;: &#39;hello&#39;}), encoding=&#39;utf8&#39;)
response = urlopen(&#39;http://httpbin.org/post&#39;, data=data)
print(response.read().decode(&#39;utf-8&#39;))
</code></pre><p>携带timeout参数打开网页1</p>
<pre><code>#  携带timeout参数打开网页1
from urllib.request import urlopen

# response = urllib.request.urlopen(&#39;http://httpbin.org/get&#39;, timeout=0.1)
response = urlopen(&#39;http://httpbin.org/get&#39;, timeout=1)
print(response.read())
</code></pre><p>携带timeout参数打开网页2</p>
<pre><code># 携带timeout参数打开网页2
from urllib.request import urlopen

try:
    response = urlopen(&#39;http://httpbin.org/get&#39;, timeout=0.1)
    print(response.read())
except Exception as e:
    print(e)
</code></pre><p>通过构建Request打开网页1</p>
<pre><code># 通过构建Request打开网页1
from urllib.request import Request
from urllib.request import urlopen

request = Request(&#39;https://python.org&#39;)
response = urlopen(request)
print(response.read().decode(&#39;utf-8&#39;))
</code></pre><p>通过构建Request打开网页2</p>
<pre><code># 通过构建Request打开网页2
from urllib.request import Request
from urllib.request import urlopen
from urllib.parse import urlencode

url = &#39;http://httpbin.org/post&#39;
headers = {
    &#39;User-Agent&#39;: &#39;Mozilla/4.0(compatibe;MSIE 5.5;Windows NT)&#39;,
    &#39;Host&#39;: &#39;httpbin.org&#39;
}
dict = {&#39;name&#39;: &#39;Germey&#39;}
data = bytes(urlencode(dict), encoding=&#39;utf8&#39;)
req = Request(url=url, data=data, headers=headers, method=&#39;POST&#39;)
response = urlopen(req)
print(response.read().decode(&#39;utf-8&#39;))
</code></pre><p>与通过构建Request打开网页2对比</p>
<pre><code># 与通过构建Request打开网页2对比
from urllib.request import Request
from urllib.request import urlopen

req = Request(url=url, data=data, method=&#39;POST&#39;)
response = urlopen(req)
print(response.read().decode(&#39;utf-8&#39;))
</code></pre><p>通过构建Request打开网页3：通过add_header方</p>
<pre><code># 通过构建Request打开网页3：通过add_header方法添加headers
from urllib.request import Request
from urllib.request import urlopen
from urllib.parse import urlencode

url = &#39;http://httpbin.org/post&#39;
dict = {&#39;name&#39;: &#39;Germey&#39;}
data = bytes(urlencode(dict), encoding=&#39;utf8&#39;)
req = Request(url=url, data=data, method=&#39;POST&#39;)
req.add_header(&#39;User-Agent&#39;, &#39;Mozilla/4.0(compatibe;MSIE 5.5;Windows NT)&#39;)
response = urlopen(req)
print(response.read().decode(&#39;utf-8&#39;))
</code></pre><p>urlencode()的使用</p>
<pre><code># urlencode()的使用
from urllib.parse import urlencode
from urllib.request import urlopen
data = {&#39;first&#39;: &#39;true&#39;, &#39;pn&#39;: 1, &#39;kd&#39;: &#39;Python&#39;}
data = urlencode(data).encode(&#39;utf-8&#39;)
data
page = urlopen(req, data=data).read()
page
</code></pre><p>使用代理打开网页</p>
<pre><code># 使用代理
from urllib.error import URLError
from urllib.request import ProxyHandler, build_opener

proxy_handler = ProxyHandler({&#39;http&#39;: &#39;106.56.102.140:8070&#39;})
opener = build_opener(proxy_handler)
try:
    response = opener.open(&#39;http://www.baidu.com/&#39;)
    print(response.read().decode(&#39;utf-8&#39;))
except URLError as e:
    print(e.reason)
</code></pre><h1 id="二、requests"><a href="#二、requests" class="headerlink" title="二、requests"></a>二、requests</h1><p>相比较urllib模块，requests模块要简单很多，但是需要单独安装：</p>
<ul>
<li>在windows系统下只需要在命令行输入命令 pip install requests 即可安装。</li>
<li>在 linux 系统下，只需要输入命令 sudo pip install requests ，即可安装。</li>
</ul>
<p>requests库的八个主要方法</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>requests.request()</td>
<td>构造一个请求，支持以下各种方法</td>
</tr>
<tr>
<td>requests.get()</td>
<td>向html网页提交get请求的方法</td>
</tr>
<tr>
<td>requests.post()</td>
<td>向html网页提交post请求的方法</td>
</tr>
<tr>
<td>requests.head()</td>
<td>获取html头部信息的主要方法</td>
</tr>
<tr>
<td>requests.put()</td>
<td>向html网页提交put请求的方法</td>
</tr>
<tr>
<td>requests.options()</td>
<td>向html网页提交options请求的方法</td>
</tr>
<tr>
<td>requests.patch()</td>
<td>向html网页提交局部修改的请求</td>
</tr>
<tr>
<td>requests.delete()</td>
<td>向html网页提交删除的请求</td>
</tr>
</tbody>
</table>
<p>请求之后，服务器通过response返回数据，response具体参数如下图：</p>
<table>
<thead>
<tr>
<th>属性</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>r.status_code</td>
<td>http请求的返回状态，若为200则表示请求成功</td>
</tr>
<tr>
<td>r.text</td>
<td>http响应内容的字符串形式，即返回的页面内容</td>
</tr>
<tr>
<td>r.encoding</td>
<td>从http header 中猜测的相应内容编码方式</td>
</tr>
<tr>
<td>r.apparent_encoding</td>
<td>从内容中分析出的响应内容编码方式（备选编码方式）</td>
</tr>
<tr>
<td>r.content</td>
<td>http响应内容的二进制形式</td>
</tr>
</tbody>
</table>
<h3 id="requests-request-method-url-kwargs"><a href="#requests-request-method-url-kwargs" class="headerlink" title="requests.request(method, url, **kwargs)"></a>requests.request(method, url, **kwargs)</h3><ul>
<li>method：即 get、post、head、put、options、patch、delete</li>
<li>url：即请求的网址</li>
<li>**kwargs：控制访问的参数，具体参数如下：</li>
<li><ul>
<li>params：字典或字节序列，作为参数增加到url中。使用这个参数可以把一些键值对以?key1=value1&amp;key2=value2的模式增加到url中</li>
</ul>
</li>
</ul>
<pre><code>## request(method, url, **kwargs)，当 **kwargs 为 params
import requests

payload = {&#39;key1&#39;: &#39;value1&#39;, &#39;key2&#39;: &#39;value2&#39;}
r = requests.request(&#39;GET&#39;, &#39;http://httpbin.org/get&#39;, params=payload)
print(r.url)
# result: http://httpbin.org/get?key1=value1&amp;key2=value2
print(r.text)
# result:
# {
#   &quot;args&quot;: {
#     &quot;key1&quot;: &quot;value1&quot;, 
#     &quot;key2&quot;: &quot;value2&quot;
#   }, 
#   &quot;headers&quot;: {
#     &quot;Accept&quot;: &quot;*/*&quot;, 
#     &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;, 
#     &quot;Connection&quot;: &quot;close&quot;, 
#     &quot;Host&quot;: &quot;httpbin.org&quot;, 
#     &quot;User-Agent&quot;: &quot;python-requests/2.19.1&quot;
#   }, 
#   &quot;origin&quot;: &quot;1.203.183.95&quot;, 
#   &quot;url&quot;: &quot;http://httpbin.org/get?key1=value1&amp;key2=value2&quot;
# }
</code></pre><ul>
<li><ul>
<li>data：字典，字节序或文件对象，重点作为向服务器提供或提交资源是提交，作为request的内容，与params不同的是，data提交的数据并不放在url链接里， 而是放在url链接对应位置的地方作为数据来存储。它也可以接受一个字符串对象。</li>
</ul>
</li>
</ul>
<pre><code>## request(method, url, **kwargs)，当 **kwargs 为 data
import requests

payload = {&#39;key1&#39;: &#39;value1&#39;, &#39;key2&#39;: &#39;value2&#39;}
r = requests.request(&#39;POST&#39;, &#39;http://httpbin.org/post&#39;, data=payload)
print(r.url)
# result: http://httpbin.org/post
print(r.text)
# result:
# {
#   &quot;args&quot;: {}, 
#   &quot;data&quot;: &quot;&quot;, 
#   &quot;files&quot;: {}, 
#   &quot;form&quot;: {
#     &quot;key1&quot;: &quot;value1&quot;, 
#     &quot;key2&quot;: &quot;value2&quot;
#   }, 
#   &quot;headers&quot;: {
#     &quot;Accept&quot;: &quot;*/*&quot;, 
#     &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;, 
#     &quot;Connection&quot;: &quot;close&quot;, 
#     &quot;Content-Length&quot;: &quot;23&quot;, 
#     &quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded&quot;, 
#     &quot;Host&quot;: &quot;httpbin.org&quot;, 
#     &quot;User-Agent&quot;: &quot;python-requests/2.19.1&quot;
#   }, 
#   &quot;json&quot;: null, 
#   &quot;origin&quot;: &quot;1.203.183.95&quot;, 
#   &quot;url&quot;: &quot;http://httpbin.org/post&quot;
# }
</code></pre><ul>
<li><ul>
<li>json：json格式的数据， json合适在相关的html，http相关的web开发中非常常见， 也是http最经常使用的数据格式， 他是作为内容部分可以向服务器提交。</li>
</ul>
</li>
</ul>
<pre><code>## request(method, url, **kwargs)，当 **kwargs 为 json
import requests

payload = {&#39;key1&#39;: &#39;value1&#39;, &#39;key2&#39;: &#39;value2&#39;}
r = requests.request(&#39;POST&#39;, &#39;http://httpbin.org/post&#39;, json=payload)
print(r.url)
# result: http://httpbin.org/post
print(r.text)
# result:
# {
#   &quot;args&quot;: {}, 
#   &quot;data&quot;: &quot;{\&quot;key1\&quot;: \&quot;value1\&quot;, \&quot;key2\&quot;: \&quot;value2\&quot;}&quot;, 
#   &quot;files&quot;: {}, 
#   &quot;form&quot;: {}, 
#   &quot;headers&quot;: {
#     &quot;Accept&quot;: &quot;*/*&quot;, 
#     &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;, 
#     &quot;Connection&quot;: &quot;close&quot;, 
#     &quot;Content-Length&quot;: &quot;36&quot;, 
#     &quot;Content-Type&quot;: &quot;application/json&quot;, 
#     &quot;Host&quot;: &quot;httpbin.org&quot;, 
#     &quot;User-Agent&quot;: &quot;python-requests/2.19.1&quot;
#   }, 
#   &quot;json&quot;: {
#     &quot;key1&quot;: &quot;value1&quot;, 
#     &quot;key2&quot;: &quot;value2&quot;
#   }, 
#   &quot;origin&quot;: &quot;1.203.183.95&quot;, 
#   &quot;url&quot;: &quot;http://httpbin.org/post&quot;
# }
</code></pre><ul>
<li><ul>
<li>files：字典， 是用来向服务器传输文件时使用的字段。</li>
</ul>
</li>
</ul>
<pre><code>## request(method, url, **kwargs)，当 **kwargs 为 file
import requests
# filejiatao.txt 文件的内容是文本“www.baidu.com www.cctvjiatao.com”
files = {&#39;file&#39;: open(r&quot;D:\DataguruPyhton\PythonSpider\lesson2\filejiatao.txt&quot;, &quot;rb&quot;)}
r = requests.request(&#39;POST&#39;, &#39;http://httpbin.org/post&#39;, files=files)
print(r.url)
# result: http://httpbin.org/post
print(r.text)
# result:
# {
#   &quot;args&quot;: {}, 
#   &quot;data&quot;: &quot;&quot;, 
#   &quot;files&quot;: {
#     &quot;file&quot;: &quot;www.baidu.com www.cctvjiatao.com&quot;
#   }, 
#   &quot;form&quot;: {}, 
#   &quot;headers&quot;: {
#     &quot;Accept&quot;: &quot;*/*&quot;, 
#     &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;, 
#     &quot;Connection&quot;: &quot;close&quot;, 
#     &quot;Content-Length&quot;: &quot;182&quot;, 
#     &quot;Content-Type&quot;: &quot;multipart/form-data; boundary=ee12ea6a4fd2b8a3318566775f2b268f&quot;, 
#     &quot;Host&quot;: &quot;httpbin.org&quot;, 
#     &quot;User-Agent&quot;: &quot;python-requests/2.19.1&quot;
#   }, 
#   &quot;json&quot;: null, 
#   &quot;origin&quot;: &quot;1.203.183.95&quot;, 
#   &quot;url&quot;: &quot;http://httpbin.org/post&quot;
# }
</code></pre><ul>
<li><ul>
<li>headers：字典是http的相关语，对应了向某个url访问时所发起的http的头字段， 可以用这个字段来定义http的访问的http头，可以用来模拟任何我们想模拟的浏览器来对url发起访问。</li>
</ul>
</li>
</ul>
<pre><code>## request(method, url, **kwargs)，当 **kwargs 为 headers
import requests

payload = {&#39;key1&#39;: &#39;value1&#39;, &#39;key2&#39;: &#39;value2&#39;}
headers = {&quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.84 Safari/537.36&quot;}
r = requests.request(&#39;GET&#39;, &#39;http://httpbin.org/get&#39;, params=payload, headers=headers)
print(r.url)
# result: http://httpbin.org/get?key1=value1&amp;key2=value2
print(r.text)
# result:
# {
#   &quot;args&quot;: {
#     &quot;key1&quot;: &quot;value1&quot;, 
#     &quot;key2&quot;: &quot;value2&quot;
#   }, 
#   &quot;headers&quot;: {
#     &quot;Accept&quot;: &quot;*/*&quot;, 
#     &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;, 
#     &quot;Connection&quot;: &quot;close&quot;, 
#     &quot;Host&quot;: &quot;httpbin.org&quot;, 
#     &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.84 Safari/537.36&quot;
#   }, 
#   &quot;origin&quot;: &quot;1.203.183.95&quot;, 
#   &quot;url&quot;: &quot;http://httpbin.org/get?key1=value1&amp;key2=value2&quot;
# }
</code></pre><ul>
<li><ul>
<li>cookies：字典或CookieJar，指的是从http中解析cookie</li>
</ul>
</li>
</ul>
<pre><code>## request(method, url, **kwargs)，当 **kwargs 为 cookies
import requests

cookies = dict(cookies_are=&#39;working&#39;)
r = requests.request(&#39;GET&#39;, &#39;http://httpbin.org/cookies&#39;, cookies=cookies)
print(r.url)
# result: http://httpbin.org/cookies
print(r.text)
# result:
# {
#   &quot;cookies&quot;: {
#     &quot;cookies_are&quot;: &quot;working&quot;
#   }
# }
</code></pre><ul>
<li><ul>
<li>auth：元组，用来支持http认证功能</li>
</ul>
</li>
</ul>
<pre><code>## request(method, url, **kwargs)，当 **kwargs 为 auth
import requests

cs_user = &#39;用户名&#39;
cs_psw = &#39;密码&#39;
r = requests.request(&#39;GET&#39;, &#39;https://api.github.com&#39;, auth=(cs_user, cs_psw))
print(r.url)
# result: 待补充
print(r.text)
# result: 待补充
</code></pre><ul>
<li><ul>
<li>timeout: 用于设定超时时间， 单位为秒，当发起一个get请求时可以设置一个timeout时间， 如果在timeout时间内请求内容没有返回， 将产生一个timeout的异常。</li>
</ul>
</li>
</ul>
<pre><code>## request(method, url, **kwargs)，当 **kwargs 为 timeout
import requests

r = requests.request(&#39;GET&#39;, &#39;http://github.com&#39;, timeout=0.001)
print(r.url)
# result: 报错 socket.timeout: timed out
</code></pre><ul>
<li><ul>
<li>proxies：字典， 用来设置访问代理服务器。</li>
</ul>
</li>
</ul>
<pre><code>## request(method, url, **kwargs)，当 **kwargs 为 proxies
import requests

proxies = {
    &#39;https&#39;: &#39;http://41.118.132.69:4433&#39;
}
# 也可以通过环境变量设置代理
# export HTTP_PROXY=&#39;http://10.10.1.10:3128&#39;
# export HTTPS_PROXY=&#39;http://10.10.1.10:1080&#39;
r = requests.request(&#39;GET&#39;, &#39;http://httpbin.org/get&#39;, proxies=proxies)
print(r.url)
# result: http://httpbin.org/get
print(r.text)
# result:
# {
#   &quot;args&quot;: {}, 
#   &quot;headers&quot;: {
#     &quot;Accept&quot;: &quot;*/*&quot;, 
#     &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;, 
#     &quot;Connection&quot;: &quot;close&quot;, 
#     &quot;Host&quot;: &quot;httpbin.org&quot;, 
#     &quot;User-Agent&quot;: &quot;python-requests/2.19.1&quot;
#   }, 
#   &quot;origin&quot;: &quot;1.203.183.95&quot;, 
#   &quot;url&quot;: &quot;http://httpbin.org/get&quot;
# }
</code></pre><ul>
<li><ul>
<li>verify：开关， 用于认证SSL证书， 默认为True</li>
</ul>
</li>
</ul>
<pre><code>## request(method, url, **kwargs)，当 **kwargs 为 verify，SSL证书验证
import requests

r = requests.request(&#39;GET&#39;, &#39;https://kyfw.12306.cn/otn/&#39;, verify=True)
print(r.text)

r = requests.request(&#39;GET&#39;, &#39;https://kyfw.12306.cn/otn/&#39;, verify=False)
print(r.text)

r = requests.request(&#39;GET&#39;, &#39;https://github.com&#39;, verify=True)
print(r.text)
</code></pre><ul>
<li><ul>
<li>allow_redirects: 开关， 表示是否允许对url进行重定向， 默认为True。</li>
</ul>
</li>
<li><ul>
<li>stream: 开关， 指是否对获取内容进行立即下载， 默认为True。</li>
</ul>
</li>
<li><ul>
<li>cert： 用于设置保存本地SSL证书路径</li>
</ul>
</li>
</ul>
<h3 id="requests-get-url-params-None-kwargs"><a href="#requests-get-url-params-None-kwargs" class="headerlink" title="requests.get(url, params=None, **kwargs)"></a>requests.get(url, params=None, **kwargs)</h3><pre><code># 官方文档
def get(url, params=None, **kwargs):
    kwargs.setdefault(&#39;allow_redirects&#39;, True)
    return request(&#39;get&#39;, url, params=params, **kwargs)
</code></pre><h3 id="requests-post-url-data-None-json-None-kwargs"><a href="#requests-post-url-data-None-json-None-kwargs" class="headerlink" title="requests.post(url, data=None, json=None, **kwargs)"></a>requests.post(url, data=None, json=None, **kwargs)</h3><pre><code># 官方文档
def post(url, data=None, json=None, **kwargs):
    return request(&#39;post&#39;, url, data=data, json=json, **kwargs)
</code></pre><h3 id="requests-head-url-kwargs"><a href="#requests-head-url-kwargs" class="headerlink" title="requests.head(url, **kwargs)"></a>requests.head(url, **kwargs)</h3><pre><code># 官方文档
def head(url, **kwargs):
    kwargs.setdefault(&#39;allow_redirects&#39;, False)
    return request(&#39;head&#39;, url, **kwargs)
</code></pre><h3 id="requests-options-url-kwargs"><a href="#requests-options-url-kwargs" class="headerlink" title="requests.options(url, **kwargs)"></a>requests.options(url, **kwargs)</h3><pre><code># 官方文档
def options(url, **kwargs):
    kwargs.setdefault(&#39;allow_redirects&#39;, True)
    return request(&#39;options&#39;, url, **kwargs)
</code></pre><h3 id="requests-put-url-data-None-kwargs"><a href="#requests-put-url-data-None-kwargs" class="headerlink" title="requests.put(url, data=None, **kwargs)"></a>requests.put(url, data=None, **kwargs)</h3><pre><code># 官方文档
def put(url, data=None, **kwargs):
    return request(&#39;put&#39;, url, data=data, **kwargs)
</code></pre><h3 id="requests-patch-url-data-None-kwargs"><a href="#requests-patch-url-data-None-kwargs" class="headerlink" title="requests.patch(url, data=None, **kwargs)"></a>requests.patch(url, data=None, **kwargs)</h3><pre><code># 官方文档
def patch(url, data=None, **kwargs):
    return request(&#39;patch&#39;, url, data=data, **kwargs)
</code></pre><blockquote>
<p>requests.patch和request.put类似。<br> 两者不同的是： 当我们用patch时仅需要提交需要修改的字段。<br> 而用put时，必须将所有字段一起提交到url，未提交字段将会被删除。<br> patch的好处是：节省网络带宽。</p>
</blockquote>
<h3 id="requests-delete-url-kwargs"><a href="#requests-delete-url-kwargs" class="headerlink" title="requests.delete(url, **kwargs)"></a>requests.delete(url, **kwargs)</h3><pre><code># 官方文档
def delete(url, **kwargs):
    return request(&#39;delete&#39;, url, **kwargs)
</code></pre><h3 id="requests库的异常"><a href="#requests库的异常" class="headerlink" title="requests库的异常"></a>requests库的异常</h3><p>注意requests库有时会产生异常，比如网络连接错误、http错误异常、重定向异常、请求url超时异常等等。所以我们需要判断r.status_codes是否是200，在这里我们怎么样去捕捉异常呢？<br> 这里我们可以利用r.raise_for_status() 语句去捕捉异常，该语句在方法内部判断r.status_code是否等于200，如果不等于，则抛出异常。<br> 于是在这里我们有一个爬取网页的通用代码框架</p>
<pre><code>try:
    r = requests.get(url, timeout=30)  # 请求超时时间为30秒
    r.raise_for_status()  # 如果状态不是200，则引发异常
    r.encoding = r.apparent_encoding  # 配置编码
    print(r.text)
except:
    print(&quot;产生异常&quot;)
</code></pre><h1 id="三、requests的综合小实例"><a href="#三、requests的综合小实例" class="headerlink" title="三、requests的综合小实例"></a>三、requests的综合小实例</h1><h3 id="实例一：京东商品信息的爬取"><a href="#实例一：京东商品信息的爬取" class="headerlink" title="实例一：京东商品信息的爬取"></a>实例一：京东商品信息的爬取</h3><pre><code>## 京东商品信息的爬取
# 不需要对头部做任何修改，即可爬网页
import requests

url = &#39;http://item.jd.com/2967929.html&#39;
try:
    r = requests.get(url, timeout=30)
    r.raise_for_status()
    r.encoding = r.apparent_encoding
    print(r.text[:1000])  # 部分信息
except:
    print(&quot;失败&quot;)
</code></pre><h3 id="实例二：亚马逊商品信息的爬取"><a href="#实例二：亚马逊商品信息的爬取" class="headerlink" title="实例二：亚马逊商品信息的爬取"></a>实例二：亚马逊商品信息的爬取</h3><pre><code>## 亚马逊商品信息的爬取
# 该网页中对爬虫进行的爬取做了限制，因此我们需要伪装自己为浏览器发出的请求
import requests

url = &#39;http://www.amazon.cn/gp/product/B01M8L5Z3Y&#39;
try:
    kv = {&#39;user_agent&#39;: &#39;Mozilla/5.0&#39;}
    r = requests.get(url, headers=kv)  # 改变自己的请求数据
    r.raise_for_status()
    r.encoding = r.apparent_encoding
    print(r.text[1000:2000])  # 部分信息
except:
    print(&quot;失败&quot;)
</code></pre><h3 id="实例三：百度搜索关键字提交"><a href="#实例三：百度搜索关键字提交" class="headerlink" title="实例三：百度搜索关键字提交"></a>实例三：百度搜索关键字提交</h3><pre><code>## 百度搜索关键字提交
# 百度的关键字接口：https://www.baidu.com/s?wd=keyword
import requests

keyword = &#39;python&#39;
try:
    kv = {&#39;wd&#39;: keyword}
    headers = {&quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.84 Safari/537.36&quot;}
    r = requests.get(&#39;https://www.baidu.com/s&#39;, params=kv, headers=headers)
    r.raise_for_status()
    r.encoding = r.apparent_encoding
    # print(len(r.text))
    print(r.text)
except:
    print(&quot;失败&quot;)
</code></pre><h3 id="实例四：网络图片的爬取"><a href="#实例四：网络图片的爬取" class="headerlink" title="实例四：网络图片的爬取"></a>实例四：网络图片的爬取</h3><pre><code>## 网络图片的爬取
import requests
import os

try:
    url = &quot;https://odonohz90.qnssl.com/library/145456/bb0b3faa7a872d012bb4c57256b47585.jpg?imageView2/2/w/1000/h/1000/q/75&quot;  # 图片地址
    root = r&quot;D:\DataguruPyhton\PythonSpider\lesson3\pic\\&quot;
    path = root + url.split(&quot;/&quot;)[-1]
    if not path.endswith(&quot;.jpg&quot;):
        path += &quot;.jpg&quot;
    if not os.path.exists(root):  # 目录不存在创建目录
        os.mkdir(root)
    if not os.path.exists(path):  # 文件不存在则下载
        r = requests.get(url)
        f = open(path, &quot;wb&quot;)
        f.write(r.content)
        f.close()
        print(&quot;文件下载成功&quot;)
    else:
        print(&quot;文件已经存在&quot;)
except:
    print(&quot;获取失败&quot;)
</code></pre>
            </div>
            <hr>

            
            <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.88rem;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-large waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fa fa-close"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            

            <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    <div class="social-share" data-disabled="qzone" data-wechat-qrcode-helper="<p>微信里点“发现”->“扫一扫”二维码便可查看分享。</p>"></div>
    
</div>

<script src="/libs/share/js/social-share.min.js"></script>

            <div class="reprint">
                <p>
                    <span class="reprint-tip">
                        <i class="fa fa-exclamation-circle"></i>&nbsp;&nbsp;转载请注明:
                    </span>
                    <a href="http://Coderzgh.github.io/Coderzgh.github.io" class="b-link-green">苦乐随缘</a>
                    <i class="fa fa-angle-right fa-lg fa-fw text-color"></i>
                    <a href="/Coderzgh.github.io/2019/05/13/python-crawler-urllib-requests-3/" class="b-link-green">Python网络爬虫实战之三：基本工具库urllib和requests</a>
                </p>
            </div>
        </div>
    </div>

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6 overflow-policy" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fa fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Coderzgh.github.io/2019/05/14/python-crawler-beautifulsoup-4/">
                    <div class="card-image">
                        
                        <img src="/source/images/xxx.jpg" class="responsive-img" alt="Python网络爬虫实战之四：BeautifulSoup">
                        
                        <span class="card-title">Python网络爬虫实战之四：BeautifulSoup</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            正文：Beautiful Soup 是一个可以从HTML或XML文件中提取数据的Python库.它能够通过你喜欢的转换器实现惯用的文档导航,查找,修改文档的方式.Beautiful Soup会帮你节省数小时甚至数天的工作时间.
安装: pi
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="fa fa-clock-o fa-fw icon-date"></i>2019-05-14
                        </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Coderzgh.github.io/categories/Python/" class="post-category" target="_blank">
                                    Python
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Coderzgh.github.io/tags/Python/" target="_blank">
                        <span class="chip bg-color">Python</span>
                    </a>
                    
                    <a href="/Coderzgh.github.io/tags/BeautifulSoup/" target="_blank">
                        <span class="chip bg-color">BeautifulSoup</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6 overflow-policy" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fa fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Coderzgh.github.io/2019/05/12/python-crawler-basic-oper-2/">
                    <div class="card-image">
                        
                        <img src="/source/images/xxx.jpg" class="responsive-img" alt="Python网络爬虫实战之二：环境部署、基础语法、文件操作">
                        
                        <span class="card-title">Python网络爬虫实战之二：环境部署、基础语法、文件操作</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            一、Python的环境部署Python安装、Python的IDE安装本文不再赘述，网上有很多教程
爬虫必备的几个库：Requests、Selenium、lxml、Beatiful Soup

Requests 是基于urllib编写的第三方
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="fa fa-clock-o fa-fw icon-date"></i>2019-05-12
                            </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Coderzgh.github.io/categories/Python/" class="post-category" target="_blank">
                                    Python
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Coderzgh.github.io/tags/Python/" target="_blank">
                        <span class="chip bg-color">Python</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>
</div>



    

</main>


<footer class="page-footer bg-color">
    <div class="container row center-align">
        <div class="col s12 m8 l8 copy-right">
            本站由&copy;<a href="https://blinkfox.github.io/" target="_blank">Blinkfox</a>基于
            <a href="https://hexo.io/" target="_blank">Hexo</a> 的
            <a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">hexo-theme-matery</a>主题搭建.

            

            
			
                <br>
                
                <span id="busuanzi_container_site_pv">
                    <i class="fa fa-heart-o"></i>
                    本站总访问量 <span id="busuanzi_value_site_pv" class="white-color"></span>
                </span>
                
                
                <span id="busuanzi_container_site_uv">
                    <i class="fa fa-users"></i>
                    次,&nbsp;访客数 <span id="busuanzi_value_site_uv" class="white-color"></span> 人.
                </span>
                
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">


    <a href="mailto:coderzgh@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fa fa-envelope-open"></i>
    </a>




</div>
    </div>
</footer>

<div class="progress-bar"></div>


<!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/Coderzgh.github.io/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
<!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fa fa-angle-up"></i>
    </a>
</div>


<script src="/libs/materialize/materialize.min.js"></script>
<script src="/libs/masonry/masonry.pkgd.min.js"></script>
<script src="/libs/aos/aos.js"></script>
<script src="/libs/scrollprogress/scrollProgress.min.js"></script>
<script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
<script src="/js/matery.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->



    <script src="/libs/others/clicklove.js"></script>


    <script async src="/libs/others/busuanzi.pure.mini.js"></script>


</body>
</html>